# ğŸ§  Symbolic Memory Network

*A Hybrid Neuro-Symbolic Reasoning Engine for Knowledge Storage, Retrieval, and Logical Inference*

---

## Overview

The **Symbolic Memory Network (SMN)** is an experimental **neuro-symbolic reasoning framework** that combines **symbolic graph-based memory** with **neural embeddings** and **LLM-based verification** to simulate structured reasoning.

It allows a user to:

* Store natural language facts into an *interpretable symbolic memory graph*
* Retrieve semantically similar knowledge using vector search
* Compose and verify reasoning chains using a hybrid **neural + symbolic inference loop**

This project demonstrates how large language models can be augmented with **structured memory**, **semantic embeddings**, and **symbolic logic patterns** â€” a crucial research direction for building *explainable and trustworthy AI systems*.

---

## Architecture Overview

### Core Components

#### 1. **Symbol Extraction Layer**

* Converts raw text into structured symbolic triples (`subject`, `predicate`, `object`).
* Uses lightweight regex-based pattern recognition (`is a`, `has`, `produces`, etc.).
* Falls back to â€œstatementâ€ nodes for unstructured input.

#### 2. **Neural Embedding Layer**

* Uses `SentenceTransformer` (MiniLM-L6-v2) to embed facts and queries into vector space.
* Enables **semantic retrieval** based on conceptual similarity.
* Supports both CPU-only and optional GPU acceleration.

#### 3. **Memory Store**

* A minimal persistent memory engine (`store.py`) for storing:

  * Symbolic items
  * Vector embeddings
  * Metadata (source, timestamp, etc.)
* Provides **brute-force similarity search** via normalized cosine similarity.

#### 4. **Retriever and Composer**

* Retrieves top-*k* relevant memories for a given query.
* Composes *chains of reasoning* where facts share overlapping entities (`subj == obj`).
* Scores chains using average similarity and ranks them.

#### 5. **Verifier (LLM Reasoner)**

* Uses `google/flan-t5-base` (through `transformers` pipeline) to verify whether a reasoning chain supports the userâ€™s query.
* Produces structured JSON responses (`{"answer": ..., "confidence": ..., "explanation": ...}`) when available.
* Falls back to heuristic scoring when the verifier is unavailable.

#### 6. **Frontend (Streamlit UI)**

* Interactive dashboard to:

  * Add knowledge facts
  * Query the system for reasoning
  * Visualize retrieved chains and memory contents
* Designed for interpretability and iterative experimentation.

---

## Data Flow

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Input (Fact or  â”‚
â”‚   Question in English) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Œâ”˜
             â”‚
             â–¼
     Symbol Extraction
 (Regex + Shallow Parsing)
             â”‚
             â–¼
   Neural Embedding (SBERT)
             â”‚
             â–¼
  MemoryStore.add(symbol, emb)
             â”‚
             â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Query: Retrieve &     â”‚
  â”‚  Compose Reason Chains  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
     LLM Verifier (Flan-T5)
     âŸ· Confidence + Rationale
             â”‚
             â–¼
  Streamlit UI: Visualization
```

---

## ğŸ§  Example Interaction

| Action          | Description                                                                                         |
| --------------- | --------------------------------------------------------------------------------------------------- |
| **Add Fact**    | â€œPhotosynthesis produces oxygenâ€ â†’ stored as symbolic relation `(photosynthesis, produces, oxygen)` |
| **Ask Query**   | â€œDoes photosynthesis generate oxygen?â€                                                              |
| **SMN Process** | Retrieves similar embeddings â†’ finds reasoning chain â†’ verifies via Flan-T5                         |
| **Output**      | â€œYes. Because photosynthesis produces oxygen.â€ (Confidence: 0.92)                                   |

---

## âš™ï¸ Technologies Used

| Layer               | Library / Tool                         | Purpose                                |
| ------------------- | -------------------------------------- | -------------------------------------- |
| **Frontend**        | `Streamlit`                            | Interactive dashboard                  |
| **Embedding**       | `Sentence-Transformers (MiniLM-L6-v2)` | Semantic encoding of text              |
| **Verification**    | `Transformers (Flan-T5)`               | Logical verification and justification |
| **Memory**          | `Numpy`, `Faiss` (optional)            | Efficient similarity search            |
| **Knowledge Graph** | `NetworkX`, `PyVis`                    | Symbolic relation visualization        |
| **Core Logic**      | Python (OOP)                           | Modular architecture for extensibility |

---

## ğŸ—‚ Repository Structure

```
ğŸ“ Symbolic-Memory-Network/
â”œâ”€ app.py                  # Streamlit frontend
â”œâ”€ core.py                 # Core reasoning engine
â”œâ”€ store.py                # Memory store implementation
â”œâ”€ requirements.txt        # Python dependencies
â””â”€ README.md               
```

---

## Key Innovations

1. **Hybrid Neuro-Symbolic Reasoning**

   * Merges dense embeddings with symbolic pattern extraction.
2. **Explainable Inference**

   * Every reasoning chain is human-readable.
3. **Lightweight Cognitive Architecture**

   * Runs entirely on CPU with optional neural modules.
4. **Modular Design**

   * Encoder, verifier, and retriever are pluggable.
5. **Self-Contained Memory**

   * Local, interpretable knowledge representation without a database.

---


### 3. Add Facts and Ask Questions

* Type sentences like:

  * â€œWater is a liquid.â€
  * â€œLiquid has molecules.â€
  * â€œDo molecules exist in water?â€
* Observe how the system reasons via retrieved symbolic chains.

---

## ğŸ§© Future Directions

* **Integration with RAG pipelines** for long-context retrieval.
* **Knowledge Graph visualization panel** for reasoning trace.
* **Local fine-tuning of verifier** for domain-specific logic.
* **Temporal reasoning and episodic memory modules.**

---

## ğŸ“ Research Context

This project represents an early attempt toward **autonomous reasoning systems** that blend symbolic structure and neural understanding.
Such hybrid systems aim to overcome the limitations of:

* Purely statistical models (which lack explainability)
* Purely symbolic systems (which lack generalization)

The **Symbolic Memory Network** aligns with active research themes in:

* **Explainable AI (XAI)**
* **Neuro-Symbolic Integration**
* **Cognitive Architectures**
* **Interpretable Machine Reasoning**

